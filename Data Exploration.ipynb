{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:26:42.558588Z",
     "start_time": "2024-07-30T14:26:42.552402Z"
    }
   },
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.impute import SimpleImputer\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# DATA SET CREATION"
   ],
   "id": "2970a132e25d7dbb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. dataset extraction"
   ],
   "id": "fab2988244b5b60e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:26:46.430257Z",
     "start_time": "2024-07-30T14:26:46.425406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open ('/tmp/pycharm_project_366/config.json', 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "#features_code_lists = config['features_code_lists']\n",
    "features_name_list = config['features_name_list']\n",
    "train_path = config['train_path']\n",
    "test_path = config['test_path']"
   ],
   "id": "447a79c9ecd39274",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv(train_path, low_memory=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T12:00:49.527938Z",
     "start_time": "2024-07-30T12:00:44.477838Z"
    }
   },
   "id": "f61cded704c98638",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlow_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/Final Project/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/Final Project/lib/python3.10/site-packages/pandas/io/parsers/readers.py:626\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[0;32m--> 626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/Final Project/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1923\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1916\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[1;32m   1917\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1918\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[1;32m   1919\u001B[0m     (\n\u001B[1;32m   1920\u001B[0m         index,\n\u001B[1;32m   1921\u001B[0m         columns,\n\u001B[1;32m   1922\u001B[0m         col_dict,\n\u001B[0;32m-> 1923\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[1;32m   1924\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[1;32m   1925\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1926\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1927\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/.virtualenvs/Final Project/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:239\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m    236\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 239\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_first_chunk:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_df.shape"
   ],
   "id": "7a54e5dbd0df4c66",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "features_code_dict = {}\n",
    "features_with_array = defaultdict(lambda: 1)\n",
    "with open('/tmp/pycharm_project_366/features_with_arrays.txt') as f:\n",
    "    for line in f:\n",
    "        feature_code, array_size = line.split()\n",
    "        features_with_array[feature_code] = int(array_size)\n",
    "\n",
    "with open('/tmp/pycharm_project_366/features.txt') as features_file:\n",
    "    for line in features_file:\n",
    "        feature_code, feature_name = line.split('\\t')\n",
    "        feature_name = feature_name.replace('\\n', '')\n",
    "        size = features_with_array[feature_code]\n",
    "        for i in range(size):\n",
    "            new_feature_code = f'{feature_code}-0.{i}'\n",
    "            new_feature_name = f'{feature_name} - {i}'\n",
    "            features_code_dict[new_feature_code] = new_feature_name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:26:50.293981Z",
     "start_time": "2024-07-30T14:26:50.287212Z"
    }
   },
   "id": "b757400a62b8bec2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "features_code_dict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84062fe693354d08",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_df = train_df.rename(columns=features_code_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T13:30:52.269051Z",
     "start_time": "2024-07-30T13:30:52.249059Z"
    }
   },
   "id": "7ccd633aa256048b",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_df \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_df\u001B[49m\u001B[38;5;241m.\u001B[39mrename(columns\u001B[38;5;241m=\u001B[39mfeatures_code_dict)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "train_df.info(verbose=True, show_counts=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b8c3502df744e62",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. FEATURE REPRESENTATION"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54dad3ac744e65f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Feature Preprocessing\n",
    "\n",
    "todo!!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3a558f8fe827665"
  },
  {
   "cell_type": "code",
   "source": [
    "with open('/tmp/pycharm_project_366/features_types.json') as f:\n",
    "    features_types = json.load(f)\n",
    "numerical_features = [f'{feature} - 0' for feature in features_types['numerical_features']]\n",
    "categorical_features = [f'{feature} - 0' for feature in features_types['categorical_features']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:27:02.369045Z",
     "start_time": "2024-07-30T14:27:02.364225Z"
    }
   },
   "id": "8e611bf34dcb289a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.1 Fill nans for numerical values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d266cc427931f16"
  },
  {
   "cell_type": "code",
   "source": [
    "mean_imputer = SimpleImputer(strategy='mean')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6275f4394821fbc5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_df[numerical_features] = mean_imputer.fit_transform(train_df[numerical_features])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8f68a8df5f3833e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.2 Fill nans for categorical values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "665267c3871f2d26"
  },
  {
   "cell_type": "code",
   "source": [
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "train_df[categorical_features] = categorical_imputer.fit_transform(train_df[categorical_features])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e68c2677073f441b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.3 Extract information from diagnoses"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe87aeb7e9c87c5c"
  },
  {
   "cell_type": "code",
   "source": [
    "diseases_patterns = [\n",
    "    ('Diabetes', r'E11'),\n",
    "    ('Pancreatic Cancer', r'C25'),\n",
    "    ('Obesity', r'E66'),\n",
    "    ('Acute Pancreatitis', r'K85'),\n",
    "    ('Alcoholic Liver Disease', r'K70'),\n",
    "    ('Cirrhosis', r'K74'),\n",
    "    ('Acute Hepatitis A', r'B15'),\n",
    "    ('Acute Hepatitis B', r'B16'),\n",
    "    ('Acute Hepatitis C', r'B171'),\n",
    "    ('Toxic Liver Disease', r'K71'),\n",
    "    ('Cushings Syndrome', r'E24'),\n",
    "    ('Hyperthyroidism', r'E05'),\n",
    "    ('Intestinal Malabsorption', r'K90'),\n",
    "    ('Arterial Embolism and Thrombosis', r'I74')\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:27:10.533293Z",
     "start_time": "2024-07-30T14:27:10.528598Z"
    }
   },
   "id": "2b409366ccd87572",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "def classify_disease(diseases_column, disease_pattern):\n",
    "    return diseases_column.str.contains(disease_pattern)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:27:12.568110Z",
     "start_time": "2024-07-30T14:27:12.564588Z"
    }
   },
   "id": "6fd706adadf10c9f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "patient_diseases = train_df['Diagnoses']\n",
    "for disease, disease_pattern in diseases_patterns[2:]:\n",
    "    train_df[f'Has {disease}'] = classify_disease(patient_diseases, disease_pattern)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T12:01:05.103002Z",
     "start_time": "2024-07-30T12:01:05.080696Z"
    }
   },
   "id": "f592d48114301cf7",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m patient_diseases \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_df\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDiagnoses\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m disease, disease_pattern \u001B[38;5;129;01min\u001B[39;00m diseases_patterns[\u001B[38;5;241m2\u001B[39m:]:\n\u001B[1;32m      3\u001B[0m     train_df[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHas \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdisease\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m classify_disease(patient_diseases, disease_pattern)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "train_df = train_df.drop(columns=['Diagnoses'])\n",
    "train_df = train_df.drop(columns=[f'Diagnoses - ICD10 - {i}' for i in range(100)])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7259d10dfeccd256",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e68b64264887c54b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.4 Extract information from family"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dce258f4ad29d2b"
  },
  {
   "cell_type": "code",
   "source": [
    "father_diagnosis_codes = [f'Illnesses of father - {i}' for i in range(10)]\n",
    "mother_diagnosis_codes = [f'Illnesses of mother - {i}' for i in range(11)]\n",
    "siblings_diagnosis_codes = [f'Illnesses of siblings - {i}' for i in range(12)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:27:16.798153Z",
     "start_time": "2024-07-30T14:27:16.794288Z"
    }
   },
   "id": "1108e3681d3927ae",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "father_diseases = train_df[father_diagnosis_codes].astype(str).agg(', '.join, axis=1)\n",
    "mother_diseases = train_df[mother_diagnosis_codes].astype(str).agg(', '.join, axis=1)\n",
    "siblings_diseases = train_df[siblings_diagnosis_codes].astype(str).agg(', '.join, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d6b56805b25aa90",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for disease, disease_pattern in diseases_patterns:\n",
    "    train_df[f'Father has {disease}'] = classify_disease(father_diseases, disease_pattern)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6553f7401d3f3ae5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for disease, disease_pattern in diseases_patterns:\n",
    "    train_df[f'Mother has {disease}'] = classify_disease(mother_diseases, disease_pattern)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5025435ac7b8afe4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for disease, disease_pattern in diseases_patterns:\n",
    "    train_df[f'Siblings have {disease}'] = classify_disease(siblings_diseases, disease_pattern)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "793947fa7ca9e72a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_df = train_df.drop(columns=(father_diagnosis_codes + mother_diagnosis_codes + siblings_diagnosis_codes))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa32a5c285a15095",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 One Hot Encoding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96a3c9fd4d363b2e"
  },
  {
   "cell_type": "code",
   "source": [
    "one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore').set_output(transform='pandas')\n",
    "one_hot_encoding = one_hot_encoder.fit_transform(train_df[categorical_features])\n",
    "train_df = pd.concat([train_df, one_hot_encoding], axis=1)\n",
    "train_df = train_df.drop(columns=categorical_features)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c5c94ee744f37e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c44791c18a055f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Feature analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2365c99ecdecf980"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2.1 feature plots"
   ],
   "id": "4e03c51a55b71c48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Label_dictionary = {0:'Control group', 1:'Pancreatic Cancer patients', 2:'Diabetes patients'}\n",
    "\n",
    "def plot_categorical_feature(data):\n",
    "    categorical_labels = data.iloc[:,1].unique()\n",
    "    grouped_data = data.groupby([data.columns[0], data.columns[1]]).size().unstack(fill_value=0)\n",
    "    #grouped_data = grouped_data.index.setnames(Label_dictionary)\n",
    "    \n",
    "    grouped_data.columns = categorical_labels\n",
    "    \n",
    "    grouped_data = grouped_data.reset_index()\n",
    "    \n",
    "    grouped_data.plot(x=data.columns[0], kind='bar', stacked=False, figsize=(10, 6))\n",
    "    \n",
    "    plt.xlabel(data.columns[1].capitalize())\n",
    "    plt.ylabel('Number of People')\n",
    "    plt.title(f'Number of People by {data.columns[0].capitalize()} and {data.columns[1].capitalize()}')\n",
    "    plt.xticks(rotation=0)\n",
    "    \n",
    "    plt.legend(title='Category', labels=categorical_labels)\n",
    "    plt.show()"
   ],
   "id": "a729d03586dd8b49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_continuous_feature(data, agg_func='mean'):\n",
    "    \n",
    "    grouped_data = data.groupby(data.columns[0])[data.columns[1]].agg(agg_func).reset_index()\n",
    "    \n",
    "    grouped_data.columns = [data.columns[0].capitalize(), f'{agg_func.capitalize()} of {data.columns[1].capitalize()}']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=data.columns[1].capitalize(), y=f'{agg_func.capitalize()} of {data.columns[1].capitalize()}', data=grouped_data, palette='viridis')\n",
    "    \n",
    "    plt.xlabel(data.columns[0].capitalize())\n",
    "    plt.ylabel(f'{agg_func.capitalize()} of {data.columns[1].capitalize()}')\n",
    "    plt.title(f'{agg_func.capitalize()} of {data.columns[1].capitalize()} by {data.columns[0].capitalize()}')\n",
    "    \n",
    "    plt.show()"
   ],
   "id": "998b00d30f5936c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2.1.1 Quality of life"
   ],
   "id": "e2b4ca23b362a716"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "categorical_features_to_plot = ['Smoking Status', 'Processed meat intake', 'Processed meat intake', 'Alcohol intake frequency']\n",
    "#continuous_features_to_plot = ['Time spent watching television (TV)', 'Time spent using computer', 'Duration of moderate activity','Overall quality of sleep in past month']\n",
    "\n",
    "for feature in categorical_features_to_plot:\n",
    "    plot_categorical_feature(train_df[['Label', f'{feature} - 0']])\n",
    "#for feature in continuous_features_to_plot:\n",
    "#    plot_categorical_feature(train_group_df[['Label', feature]])"
   ],
   "id": "c5c0f269dfee57aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_df.info(verbose=True, show_counts=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b07cf2634948885e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 Training the Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "911cb4add67928d7"
  },
  {
   "cell_type": "code",
   "source": [
    "y = train_df['Label']\n",
    "x = train_df.drop(['Label', 'eid'], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19a3db1c12e1d22c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "rf_model = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='accuracy')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "833a116d7412d4e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "grid_search.fit(x,y)\n",
    "best_model = grid_search.best_estimator_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b8119192c6fe392",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "80ecbf14e96fff76"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4 Evaluate Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6828dd39584f8620"
  },
  {
   "cell_type": "code",
   "source": [
    "test_df = pd.read_csv(test_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:27:30.403867Z",
     "start_time": "2024-07-30T14:27:24.385231Z"
    }
   },
   "id": "32fd959a7340486e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "test_df = test_df.rename(columns=features_code_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:27:32.807223Z",
     "start_time": "2024-07-30T14:27:32.432824Z"
    }
   },
   "id": "18f49622c8782d00",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "one_hot_encoder = pickle.load(open('/tmp/pycharm_project_366/Models/One_Hot_Encoder.pk1', 'rb'))\n",
    "mean_imputer = pickle.load(open('/tmp/pycharm_project_366/Models/Mean_Imputer.pk1' , 'rb'))\n",
    "categorical_imputer = pickle.load(open('/tmp/pycharm_project_366/Models/Categorical_Imputer.pk1', 'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:27:33.423445Z",
     "start_time": "2024-07-30T14:27:33.405498Z"
    }
   },
   "id": "f62c07f59127fe27",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "test_df[numerical_features] = mean_imputer.transform(test_df[numerical_features])\n",
    "del mean_imputer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:27:35.424955Z",
     "start_time": "2024-07-30T14:27:34.415909Z"
    }
   },
   "id": "89f630539d4d0aee",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "test_df[categorical_features] = categorical_imputer.transform(test_df[categorical_features])\n",
    "del categorical_imputer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:27:36.652262Z",
     "start_time": "2024-07-30T14:27:36.599386Z"
    }
   },
   "id": "dd989740ba969fae",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "patient_diseases = test_df['Diagnoses']\n",
    "for disease, disease_pattern in diseases_patterns[2:]:\n",
    "    test_df[f'Has {disease}'] = classify_disease(patient_diseases, disease_pattern)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:27:43.709093Z",
     "start_time": "2024-07-30T14:27:42.977139Z"
    }
   },
   "id": "d30d3acb686f0b0a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1392979/826047092.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Has {disease}'] = classify_disease(patient_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/826047092.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Has {disease}'] = classify_disease(patient_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/826047092.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Has {disease}'] = classify_disease(patient_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/826047092.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Has {disease}'] = classify_disease(patient_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/826047092.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Has {disease}'] = classify_disease(patient_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/826047092.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Has {disease}'] = classify_disease(patient_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/826047092.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Has {disease}'] = classify_disease(patient_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/826047092.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Has {disease}'] = classify_disease(patient_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/826047092.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Has {disease}'] = classify_disease(patient_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/826047092.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Has {disease}'] = classify_disease(patient_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/826047092.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Has {disease}'] = classify_disease(patient_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/826047092.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Has {disease}'] = classify_disease(patient_diseases, disease_pattern)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "test_df = test_df.drop(columns=['Diagnoses'])\n",
    "test_df = test_df.drop(columns=[f'Diagnoses - ICD10 - {i}' for i in range(100)])\n",
    "test_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:27:45.317360Z",
     "start_time": "2024-07-30T14:27:44.965933Z"
    }
   },
   "id": "ce8c20797c2f4792",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            eid  Year of birth - 0  Duration of walks - 0  \\\n",
       "0       1000048             1939.0               40.00000   \n",
       "1       1000123             1944.0               30.00000   \n",
       "2       1000131             1955.0               52.79135   \n",
       "3       1000219             1962.0               15.00000   \n",
       "4       1000238             1950.0               20.00000   \n",
       "...         ...                ...                    ...   \n",
       "100761  6023700             1958.0               30.00000   \n",
       "100762  6023778             1950.0               60.00000   \n",
       "100763  6023994             1965.0               20.00000   \n",
       "100764  6024004             1960.0               30.00000   \n",
       "100765  6024050             1948.0               30.00000   \n",
       "\n",
       "        Number of days/week of moderate physical activity 10+ minutes - 0  \\\n",
       "0                                                     7.0                   \n",
       "1                                                     0.0                   \n",
       "2                                                     0.0                   \n",
       "3                                                     0.0                   \n",
       "4                                                     1.0                   \n",
       "...                                                   ...                   \n",
       "100761                                                2.0                   \n",
       "100762                                                1.0                   \n",
       "100763                                                7.0                   \n",
       "100764                                                3.0                   \n",
       "100765                                                0.0                   \n",
       "\n",
       "        Duration of moderate activity - 0  \\\n",
       "0                               20.000000   \n",
       "1                               59.181126   \n",
       "2                               59.181126   \n",
       "3                               59.181126   \n",
       "4                               20.000000   \n",
       "...                                   ...   \n",
       "100761                          10.000000   \n",
       "100762                          20.000000   \n",
       "100763                          30.000000   \n",
       "100764                         300.000000   \n",
       "100765                          59.181126   \n",
       "\n",
       "        Number of days/week of vigorous physical activity 10+ minutes - 0  \\\n",
       "0                                                     1.0                   \n",
       "1                                                     0.0                   \n",
       "2                                                     0.0                   \n",
       "3                                                     0.0                   \n",
       "4                                                     0.0                   \n",
       "...                                                   ...                   \n",
       "100761                                                1.0                   \n",
       "100762                                                0.0                   \n",
       "100763                                                3.0                   \n",
       "100764                                                2.0                   \n",
       "100765                                                0.0                   \n",
       "\n",
       "        Duration of vigorous activity - 0  Duration of strenuous sports - 0  \\\n",
       "0                               60.000000                               3.0   \n",
       "1                               40.099832                               3.0   \n",
       "2                               40.099832                               3.0   \n",
       "3                               40.099832                               3.0   \n",
       "4                               40.099832                               3.0   \n",
       "...                                   ...                               ...   \n",
       "100761                          -1.000000                               3.0   \n",
       "100762                          40.099832                               3.0   \n",
       "100763                          20.000000                               3.0   \n",
       "100764                         120.000000                               4.0   \n",
       "100765                          40.099832                               3.0   \n",
       "\n",
       "        Time spent watching television (TV) - 0  \\\n",
       "0                                           2.0   \n",
       "1                                           4.0   \n",
       "2                                           4.0   \n",
       "3                                           2.0   \n",
       "4                                           3.0   \n",
       "...                                         ...   \n",
       "100761                                      0.0   \n",
       "100762                                      3.0   \n",
       "100763                                      2.0   \n",
       "100764                                      1.0   \n",
       "100765                                      3.0   \n",
       "\n",
       "        Time spent using computer - 0  ...  Has Alcoholic Liver Disease  \\\n",
       "0                                 1.0  ...                        False   \n",
       "1                               -10.0  ...                        False   \n",
       "2                                 2.0  ...                        False   \n",
       "3                               -10.0  ...                        False   \n",
       "4                               -10.0  ...                        False   \n",
       "...                               ...  ...                          ...   \n",
       "100761                            3.0  ...                        False   \n",
       "100762                            1.0  ...                        False   \n",
       "100763                            2.0  ...                        False   \n",
       "100764                            0.0  ...                        False   \n",
       "100765                          -10.0  ...                        False   \n",
       "\n",
       "        Has Cirrhosis  Has Acute Hepatitis A  Has Acute Hepatitis B  \\\n",
       "0               False                  False                  False   \n",
       "1               False                  False                  False   \n",
       "2               False                  False                  False   \n",
       "3               False                  False                  False   \n",
       "4               False                  False                  False   \n",
       "...               ...                    ...                    ...   \n",
       "100761          False                  False                  False   \n",
       "100762          False                  False                  False   \n",
       "100763          False                  False                  False   \n",
       "100764          False                  False                  False   \n",
       "100765          False                  False                  False   \n",
       "\n",
       "        Has Acute Hepatitis C  Has Toxic Liver Disease  Has Cushings Syndrome  \\\n",
       "0                       False                    False                  False   \n",
       "1                       False                    False                  False   \n",
       "2                       False                    False                  False   \n",
       "3                       False                    False                  False   \n",
       "4                       False                    False                  False   \n",
       "...                       ...                      ...                    ...   \n",
       "100761                  False                    False                  False   \n",
       "100762                  False                    False                  False   \n",
       "100763                  False                    False                  False   \n",
       "100764                  False                    False                  False   \n",
       "100765                  False                    False                  False   \n",
       "\n",
       "        Has Hyperthyroidism  Has Intestinal Malabsorption  \\\n",
       "0                     False                         False   \n",
       "1                     False                         False   \n",
       "2                     False                         False   \n",
       "3                     False                         False   \n",
       "4                     False                         False   \n",
       "...                     ...                           ...   \n",
       "100761                False                         False   \n",
       "100762                False                         False   \n",
       "100763                False                         False   \n",
       "100764                False                         False   \n",
       "100765                False                         False   \n",
       "\n",
       "        Has Arterial Embolism and Thrombosis  \n",
       "0                                      False  \n",
       "1                                      False  \n",
       "2                                      False  \n",
       "3                                      False  \n",
       "4                                      False  \n",
       "...                                      ...  \n",
       "100761                                 False  \n",
       "100762                                 False  \n",
       "100763                                 False  \n",
       "100764                                 False  \n",
       "100765                                 False  \n",
       "\n",
       "[100766 rows x 193 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>Year of birth - 0</th>\n",
       "      <th>Duration of walks - 0</th>\n",
       "      <th>Number of days/week of moderate physical activity 10+ minutes - 0</th>\n",
       "      <th>Duration of moderate activity - 0</th>\n",
       "      <th>Number of days/week of vigorous physical activity 10+ minutes - 0</th>\n",
       "      <th>Duration of vigorous activity - 0</th>\n",
       "      <th>Duration of strenuous sports - 0</th>\n",
       "      <th>Time spent watching television (TV) - 0</th>\n",
       "      <th>Time spent using computer - 0</th>\n",
       "      <th>...</th>\n",
       "      <th>Has Alcoholic Liver Disease</th>\n",
       "      <th>Has Cirrhosis</th>\n",
       "      <th>Has Acute Hepatitis A</th>\n",
       "      <th>Has Acute Hepatitis B</th>\n",
       "      <th>Has Acute Hepatitis C</th>\n",
       "      <th>Has Toxic Liver Disease</th>\n",
       "      <th>Has Cushings Syndrome</th>\n",
       "      <th>Has Hyperthyroidism</th>\n",
       "      <th>Has Intestinal Malabsorption</th>\n",
       "      <th>Has Arterial Embolism and Thrombosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000048</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>40.00000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000123</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.181126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.099832</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000131</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>52.79135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.181126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.099832</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000219</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.181126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.099832</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000238</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.099832</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100761</th>\n",
       "      <td>6023700</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100762</th>\n",
       "      <td>6023778</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.099832</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100763</th>\n",
       "      <td>6023994</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100764</th>\n",
       "      <td>6024004</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100765</th>\n",
       "      <td>6024050</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.181126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.099832</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100766 rows  193 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "father_diseases = test_df[father_diagnosis_codes].astype(str).agg(', '.join, axis=1)\n",
    "mother_diseases = test_df[mother_diagnosis_codes].astype(str).agg(', '.join, axis=1)\n",
    "siblings_diseases = test_df[siblings_diagnosis_codes].astype(str).agg(', '.join, axis=1)\n",
    "for disease, disease_pattern in diseases_patterns:\n",
    "    test_df[f'Father has {disease}'] = classify_disease(father_diseases, disease_pattern)\n",
    "for disease, disease_pattern in diseases_patterns:\n",
    "    test_df[f'Mother has {disease}'] = classify_disease(mother_diseases, disease_pattern)\n",
    "for disease, disease_pattern in diseases_patterns:\n",
    "    test_df[f'Siblings have {disease}'] = classify_disease(siblings_diseases, disease_pattern)\n",
    "test_df = test_df.drop(columns=(father_diagnosis_codes + mother_diagnosis_codes + siblings_diagnosis_codes))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:27:53.700339Z",
     "start_time": "2024-07-30T14:27:48.558412Z"
    }
   },
   "id": "d40627b9b9406e43",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1392979/1339815279.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Father has {disease}'] = classify_disease(father_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Father has {disease}'] = classify_disease(father_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Father has {disease}'] = classify_disease(father_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Father has {disease}'] = classify_disease(father_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Father has {disease}'] = classify_disease(father_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Father has {disease}'] = classify_disease(father_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Father has {disease}'] = classify_disease(father_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Father has {disease}'] = classify_disease(father_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Father has {disease}'] = classify_disease(father_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Father has {disease}'] = classify_disease(father_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Father has {disease}'] = classify_disease(father_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Father has {disease}'] = classify_disease(father_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Father has {disease}'] = classify_disease(father_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Father has {disease}'] = classify_disease(father_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Mother has {disease}'] = classify_disease(mother_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Mother has {disease}'] = classify_disease(mother_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Mother has {disease}'] = classify_disease(mother_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Mother has {disease}'] = classify_disease(mother_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Mother has {disease}'] = classify_disease(mother_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Mother has {disease}'] = classify_disease(mother_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Mother has {disease}'] = classify_disease(mother_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Mother has {disease}'] = classify_disease(mother_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Mother has {disease}'] = classify_disease(mother_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Mother has {disease}'] = classify_disease(mother_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Mother has {disease}'] = classify_disease(mother_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Mother has {disease}'] = classify_disease(mother_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Mother has {disease}'] = classify_disease(mother_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Mother has {disease}'] = classify_disease(mother_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Siblings have {disease}'] = classify_disease(siblings_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Siblings have {disease}'] = classify_disease(siblings_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Siblings have {disease}'] = classify_disease(siblings_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Siblings have {disease}'] = classify_disease(siblings_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Siblings have {disease}'] = classify_disease(siblings_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Siblings have {disease}'] = classify_disease(siblings_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Siblings have {disease}'] = classify_disease(siblings_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Siblings have {disease}'] = classify_disease(siblings_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Siblings have {disease}'] = classify_disease(siblings_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Siblings have {disease}'] = classify_disease(siblings_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Siblings have {disease}'] = classify_disease(siblings_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Siblings have {disease}'] = classify_disease(siblings_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Siblings have {disease}'] = classify_disease(siblings_diseases, disease_pattern)\n",
      "/tmp/ipykernel_1392979/1339815279.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'Siblings have {disease}'] = classify_disease(siblings_diseases, disease_pattern)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "one_hot_encoding = one_hot_encoder.transform(test_df[categorical_features])\n",
    "test_df = pd.concat([test_df, one_hot_encoding], axis=1)\n",
    "test_df = test_df.drop(columns=categorical_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:27:55.343228Z",
     "start_time": "2024-07-30T14:27:54.456165Z"
    }
   },
   "id": "dcffa0a1ed385cd4",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:27:57.107055Z",
     "start_time": "2024-07-30T14:27:56.850257Z"
    }
   },
   "cell_type": "code",
   "source": "test_df = test_df.drop(columns=['Glycated haemoglobin (HbA1c) - 0'])",
   "id": "210c5f11ba234ef3",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "test_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a7440b1f491faff",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_test = test_df['Label']\n",
    "x_test = test_df.drop(columns=['Label', 'eid'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:28:01.860413Z",
     "start_time": "2024-07-30T14:28:01.529846Z"
    }
   },
   "id": "cb958b3bc7512005",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T14:28:47.475628Z",
     "start_time": "2024-07-30T14:28:47.402635Z"
    }
   },
   "cell_type": "code",
   "source": "model = pickle.load(open('/tmp/pycharm_project_366/Models/Best_Model_GBC_with_Weights.pk1', 'rb'))",
   "id": "dc55590cd2f305cf",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a3d8a1c5838eec1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_predictions = model.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:29:04.360734Z",
     "start_time": "2024-07-30T14:28:50.295012Z"
    }
   },
   "id": "8ea1b43189ded549",
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "test_score = accuracy_score(y_test, y_predictions)\n",
    "print(f'Accuracy on test set: {test_score}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:29:07.125930Z",
     "start_time": "2024-07-30T14:29:07.106516Z"
    }
   },
   "id": "378ded5967657d11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.6357005339102475\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "confusion_mat = confusion_matrix(y_test, y_predictions)\n",
    "print(confusion_mat)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:29:16.077959Z",
     "start_time": "2024-07-30T14:29:16.049048Z"
    }
   },
   "id": "6ea88e6903e299f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[57692 20793 13244]\n",
      " [  123   166   100]\n",
      " [ 1096  1353  6199]]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "classification_report_str = classification_report(y_test, y_predictions, target_names=['Healthy', 'Pancreatic Cancer', 'T2D'])\n",
    "print(\"Classification Report:\\n\", classification_report_str)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T14:29:23.762299Z",
     "start_time": "2024-07-30T14:29:23.527169Z"
    }
   },
   "id": "cb78f42e391521ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Healthy       0.98      0.63      0.77     91729\n",
      "Pancreatic Cancer       0.01      0.43      0.01       389\n",
      "              T2D       0.32      0.72      0.44      8648\n",
      "\n",
      "         accuracy                           0.64    100766\n",
      "        macro avg       0.43      0.59      0.41    100766\n",
      "     weighted avg       0.92      0.64      0.74    100766\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = pickle.load(open('/tmp/pycharm_project_366/Models/Best_Model.pk1', 'rb'))",
   "id": "dc67f675f66882a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "importances = model.feature_importances_\n",
    "feature_names = test_df.drop(columns=['Label', 'eid']).columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "importance_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T12:05:01.004420Z",
     "start_time": "2024-07-30T12:05:00.907793Z"
    }
   },
   "id": "74b9ebb9c6e29502",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                         Feature  Importance\n",
       "103                                  Glucose - 0    0.229636\n",
       "11                     Body mass index (BMI) - 0    0.138508\n",
       "0                              Year of birth - 0    0.106045\n",
       "98                               Cholesterol - 0    0.051544\n",
       "129                                  Has Obesity    0.034850\n",
       "..                                           ...         ...\n",
       "152                   Father has Hyperthyroidism    0.000000\n",
       "153          Father has Intestinal Malabsorption    0.000000\n",
       "154  Father has Arterial Embolism and Thrombosis    0.000000\n",
       "155                          Mother has Diabetes    0.000000\n",
       "146                         Father has Cirrhosis    0.000000\n",
       "\n",
       "[267 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Glucose - 0</td>\n",
       "      <td>0.229636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Body mass index (BMI) - 0</td>\n",
       "      <td>0.138508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Year of birth - 0</td>\n",
       "      <td>0.106045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Cholesterol - 0</td>\n",
       "      <td>0.051544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Has Obesity</td>\n",
       "      <td>0.034850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Father has Hyperthyroidism</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Father has Intestinal Malabsorption</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Father has Arterial Embolism and Thrombosis</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Mother has Diabetes</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Father has Cirrhosis</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>267 rows  2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T13:31:52.045344Z",
     "start_time": "2024-07-30T13:31:51.841359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_cancer_healthy = test_df[test_df['Label'] != 2]\n",
    "test_T2D_healthy = test_df[test_df['Label'] != 1]\n",
    "test_cancer_T2D = test_df[test_df['Label'] != 0]\n",
    "\n",
    "dfs = [test_cancer_healthy, test_T2D_healthy, test_cancer_T2D]\n",
    "names = ['cancer_healthy', 'T2D_healthy', 'cancer_T2D']"
   ],
   "id": "444fa1af2ff14244",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T13:32:15.645233Z",
     "start_time": "2024-07-30T13:32:11.814693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for df, name in zip(dfs, names):\n",
    "    print(f\"Loading {name}\")\n",
    "    model = pickle.load(open(f'/tmp/pycharm_project_366/Models/{name}.pk1', 'rb'))\n",
    "    \n",
    "    y_test = df['Label']\n",
    "    x_test = df.drop(columns=['Label', 'eid'])\n",
    "\n",
    "    y_predictions = model.predict(x_test)\n",
    "    test_score = accuracy_score(y_test, y_predictions)\n",
    "    print(f'Accuracy on test set: {test_score}')\n",
    "    confusion_mat = confusion_matrix(y_test, y_predictions)\n",
    "    print(confusion_mat)\n",
    "    classification_report_str = classification_report(y_test, y_predictions)\n",
    "    print(\"Classification Report:\\n\", classification_report_str)\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    feature_names = test_df.drop(columns=['Label', 'eid']).columns\n",
    "    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "    print(importance_df)"
   ],
   "id": "168fd053dfeebe75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cancer_healthy\n",
      "Accuracy on test set: 0.994181376061139\n",
      "[[91568   161]\n",
      " [  375    14]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     91729\n",
      "           1       0.08      0.04      0.05       389\n",
      "\n",
      "    accuracy                           0.99     92118\n",
      "   macro avg       0.54      0.52      0.52     92118\n",
      "weighted avg       0.99      0.99      0.99     92118\n",
      "\n",
      "                                Feature  Importance\n",
      "103                         Glucose - 0    0.150825\n",
      "0                     Year of birth - 0    0.136343\n",
      "130              Has Acute Pancreatitis    0.129927\n",
      "106                      LDL direct - 0    0.041472\n",
      "101                      Cystatin C - 0    0.030762\n",
      "..                                  ...         ...\n",
      "142        Father has Pancreatic Cancer    0.000000\n",
      "143                  Father has Obesity    0.000000\n",
      "144       Father has Acute Pancreatitis    0.000000\n",
      "145  Father has Alcoholic Liver Disease    0.000000\n",
      "129                         Has Obesity    0.000000\n",
      "\n",
      "[267 rows x 2 columns]\n",
      "Loading T2D_healthy\n",
      "Accuracy on test set: 0.8191717226057762\n",
      "[[75476 16253]\n",
      " [ 1898  6750]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.82      0.89     91729\n",
      "           2       0.29      0.78      0.43      8648\n",
      "\n",
      "    accuracy                           0.82    100377\n",
      "   macro avg       0.63      0.80      0.66    100377\n",
      "weighted avg       0.92      0.82      0.85    100377\n",
      "\n",
      "                           Feature  Importance\n",
      "103                    Glucose - 0    0.347272\n",
      "11       Body mass index (BMI) - 0    0.216047\n",
      "98                 Cholesterol - 0    0.072840\n",
      "129                    Has Obesity    0.039437\n",
      "0                Year of birth - 0    0.039347\n",
      "..                             ...         ...\n",
      "131    Has Alcoholic Liver Disease    0.000000\n",
      "133          Has Acute Hepatitis A    0.000000\n",
      "134          Has Acute Hepatitis B    0.000000\n",
      "135          Has Acute Hepatitis C    0.000000\n",
      "120  Cholesteryl Esters in LDL - 0    0.000000\n",
      "\n",
      "[267 rows x 2 columns]\n",
      "Loading cancer_T2D\n",
      "Accuracy on test set: 0.956401460661724\n",
      "[[  11  378]\n",
      " [  16 8632]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.03      0.05       389\n",
      "           2       0.96      1.00      0.98      8648\n",
      "\n",
      "    accuracy                           0.96      9037\n",
      "   macro avg       0.68      0.51      0.52      9037\n",
      "weighted avg       0.93      0.96      0.94      9037\n",
      "\n",
      "                                         Feature  Importance\n",
      "11                     Body mass index (BMI) - 0    0.175745\n",
      "103                                  Glucose - 0    0.149788\n",
      "98                               Cholesterol - 0    0.081431\n",
      "111                                     SHBG - 0    0.060599\n",
      "104                          HDL cholesterol - 0    0.044208\n",
      "..                                           ...         ...\n",
      "17      ZEBRA antigen for Epstein-Barr Virus - 0    0.000000\n",
      "18       EA-D antigen for Epstein-Barr Virus - 0    0.000000\n",
      "20   pp 52 antigen for Human Cytomegalovirus - 0    0.000000\n",
      "21   pp 28 antigen for Human Cytomegalovirus - 0    0.000000\n",
      "22      IE1A antigen for Human Herpesvirus-6 - 0    0.000000\n",
      "\n",
      "[267 rows x 2 columns]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b08d169b4453fa1f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
